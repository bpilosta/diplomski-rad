{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "#  Rain tomorrow prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "## Učitavanje biblioteka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvGPUQaHhXfL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcija za računanje metrika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcija za računanje metrika\n",
    "def metrike(modeli, testData, y_test, time):\n",
    "    for ind, model in enumerate(modeli):\n",
    "        print(F\"Algoritam: {type(model.optimizer).__name__}\")\n",
    "        #ako je ANN\n",
    "        y_pred = model.predict(testData)\n",
    "        y_pred = (y_pred > 0.5)\n",
    "        print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "        print('ROC AUC:', metrics.roc_auc_score(y_test, y_pred))\n",
    "        print(\"Confusion matrix\")\n",
    "        CM = metrics.confusion_matrix(y_test, y_pred) #confusion matrica\n",
    "        TN = CM[0, 0]\n",
    "        TP = CM[1, 1]\n",
    "        FP = CM[0, 1]\n",
    "        FN = CM[1, 0]\n",
    "        print(\"    P0           P1\")\n",
    "        print(f\"S0  {TN}        {FP}\")\n",
    "        print(f\"S1  {FN}        {TP}\")\n",
    "        print(\"Recall: \",metrics.recall_score(y_test,y_pred))\n",
    "        print(\"Precision: \",  metrics.precision_score(y_test, y_pred))\n",
    "        print(\"F1 score: \", metrics.f1_score(y_test, y_pred))\n",
    "        print(f\"Training time (sec): {time[ind]}\" )\n",
    "        print(\"-----------------------------------------------\")\n",
    "def metrike_table(modeli, testData, y_test, tr_time, histories):\n",
    "    data = []\n",
    "    for ind, model in enumerate(modeli):\n",
    "        start = time.time()\n",
    "        y_pred = model.predict(testData)\n",
    "        y_pred = (y_pred > 0.5)\n",
    "        test_time = time.time()-start\n",
    "        data.append([\n",
    "            type(model.optimizer).__name__,\n",
    "            metrics.accuracy_score(y_test, y_pred),\n",
    "            metrics.roc_auc_score(y_test, y_pred),\n",
    "            metrics.recall_score(y_test,y_pred),\n",
    "            metrics.precision_score(y_test, y_pred),\n",
    "            metrics.f1_score(y_test, y_pred),\n",
    "            tr_time[ind],\n",
    "            test_time,\n",
    "            len(histories[ind].history['loss'])\n",
    "            ])\n",
    "        plt.plot(pd.DataFrame(histories[ind].history[\"accuracy\"]))\n",
    "        plt.plot(pd.DataFrame(histories[ind].history[\"val_accuracy\"]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title(f'{type(model.optimizer).__name__} accuracy')\n",
    "        plt.figure(figsize=(6,6), dpi=500)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(pd.DataFrame(histories[ind].history[\"loss\"]))\n",
    "        plt.plot(pd.DataFrame(histories[ind].history[\"val_loss\"]))\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'{type(model.optimizer).__name__} loss')\n",
    "        plt.figure(figsize=(6,6), dpi=500)\n",
    "        plt.show()\n",
    "    df = pd.DataFrame(data, columns = ['Algoritam', \"Accuracy\",'ROC AUC',\"Recall\",\"Precision\",\"F1 score\", \"Training time (sec)\",\"Test time (sec)\",'Epochs'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "## Učitavanje skupa podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M52QDmyzhh9s"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/rain_australia.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza skupa podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['RainTomorrow'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rain = dataset['RainTomorrow'].value_counts()[0]\n",
    "rain = dataset['RainTomorrow'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.bar(['Rain','No rain'],[rain,no_rain])\n",
    "plt.ylabel(\"Number of days\")\n",
    "plt.title(\"Rain/no rain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['RainTomorrow'].value_counts()[1] /len(dataset)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['RainTomorrow'] = dataset['RainTomorrow'].replace(['No','Yes'],[0,1])\n",
    "dataset['RainToday'] = dataset['RainToday'].replace(['No','Yes'],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(dataset['Date'])\n",
    "dataset['Day'] = dates.dt.day\n",
    "dataset['Month'] = dates.dt.month\n",
    "dataset['Year'] = dates.dt.year\n",
    "dataset = dataset.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korelacijska_matrica = dataset.corr()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(korelacijska_matrica, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Čišćenje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:,dataset.columns ].dropna(axis=1, how='all').isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['RainToday'].notna()]\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['RainTomorrow'].notna()]\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_elements = ['Location','WindGustDir','WindDir9am','WindDir3pm']\n",
    "object_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "for el in object_elements:\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='Unknown')\n",
    "    imputer.fit(dataset[[el]])\n",
    "    dataset[[el]] = imputer.transform(dataset[[el]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_elements = []\n",
    "for element in dataset.columns:\n",
    "    if element not in object_elements:\n",
    "        float_elements.append(element)\n",
    "float_elements.remove('RainToday')\n",
    "float_elements.remove('RainTomorrow')\n",
    "print(float_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "for el in float_elements:\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imputer.fit(dataset[[el]])\n",
    "    dataset[[el]] = imputer.transform(dataset[[el]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korelacijska_matrica = dataset.corr()\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(korelacijska_matrica, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(korelacijska_matrica['RainTomorrow'].drop(['RainTomorrow']).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.drop(['RainTomorrow'], axis=1)\n",
    "Y=dataset['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(object_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for el in object_elements:\n",
    "    le = LabelEncoder()\n",
    "    X[el] = le.fit_transform(X[el])\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "## Podjela na trening i test skupove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVzJWAXIhxoC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kW3c7UYih0hT"
   },
   "source": [
    "## Standardizacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fQlDPKCh8sc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bb6jCOCQiAmP"
   },
   "source": [
    "## ANN - ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2356,
     "status": "ok",
     "timestamp": 1588492962262,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "e0pFVAmciHQs",
    "outputId": "8cb18c23-669b-452a-9bee-b2f96534f0f5"
   },
   "outputs": [],
   "source": [
    "ann_adam = tf.keras.models.Sequential()\n",
    "#2 skirvena sloja sa po 16 i 32 neurona\n",
    "ann_adam.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "ann_adam.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "# Dodavanje izlaznog sloja\n",
    "ann_adam.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "# kompajliranje mreže\n",
    "ann_adam.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "adam_history = ann_adam.fit(X_train, y_train, batch_size = 16, epochs = 19, validation_data=(X_test,y_test))\n",
    "adam_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrike([ann_adam], X_test, y_test, [adam_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(adam_history.history[\"accuracy\"]))\n",
    "plt.plot(pd.DataFrame(adam_history.history[\"val_accuracy\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pd.DataFrame(adam_history.history[\"loss\"]))\n",
    "plt.plot(pd.DataFrame(adam_history.history[\"val_loss\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - ADAMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ann_adamax = tf.keras.models.Sequential()\n",
    "ann_adam.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "ann_adam.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "ann_adamax.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann_adamax.compile(optimizer = 'adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "adamax_history = ann_adamax.fit(X_train, y_train, batch_size = 16, epochs = 35, validation_data=(X_test,y_test))\n",
    "adamax_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrike([ann_adamax], X_test, y_test, [adamax_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(adamax_history.history[\"accuracy\"]))\n",
    "plt.plot(pd.DataFrame(adamax_history.history[\"val_accuracy\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pd.DataFrame(adamax_history.history[\"loss\"]))\n",
    "plt.plot(pd.DataFrame(adamax_history.history[\"val_loss\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - ADAGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ann_adagrad = tf.keras.models.Sequential()\n",
    "ann_adagrad.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "ann_adagrad.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "ann_adagrad.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann_adagrad.compile(optimizer = 'adagrad', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "adagrad_history = ann_adagrad.fit(X_train, y_train, batch_size = 16, epochs = 150, validation_data=(X_test,y_test))\n",
    "adagrad_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrike([ann_adagrad], X_test, y_test, [adagrad_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(adagrad_history.history[\"accuracy\"]))\n",
    "plt.plot(pd.DataFrame(adagrad_history.history[\"val_accuracy\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pd.DataFrame(adagrad_history.history[\"loss\"]))\n",
    "plt.plot(pd.DataFrame(adagrad_history.history[\"val_loss\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - NADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_nadam = tf.keras.models.Sequential()\n",
    "ann_nadam.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "ann_nadam.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "ann_nadam.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann_nadam.compile(optimizer = 'nadam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "nadam_history = ann_nadam.fit(X_train, y_train, batch_size = 16, epochs = 18, validation_data=(X_test,y_test))\n",
    "nadam_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrike([ann_nadam], X_test, y_test, [nadam_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(nadam_history.history[\"accuracy\"]))\n",
    "plt.plot(pd.DataFrame(nadam_history.history[\"val_accuracy\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pd.DataFrame(nadam_history.history[\"loss\"]))\n",
    "plt.plot(pd.DataFrame(nadam_history.history[\"val_loss\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_sgd = tf.keras.models.Sequential()\n",
    "ann_sgd.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "ann_sgd.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "ann_sgd.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann_sgd.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sgd_history = ann_sgd.fit(X_train, y_train, batch_size = 16, epochs = 55, validation_data=(X_test,y_test))\n",
    "sgd_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrike([ann_sgd], X_test, y_test, [sgd_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(sgd_history.history[\"accuracy\"]))\n",
    "plt.plot(pd.DataFrame(sgd_history.history[\"val_accuracy\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pd.DataFrame(sgd_history.history[\"loss\"]))\n",
    "plt.plot(pd.DataFrame(sgd_history.history[\"val_loss\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN - RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_rms = tf.keras.models.Sequential()\n",
    "ann_rms.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "ann_rms.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "ann_rms.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "ann_rms.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rms_history = ann_rms.fit(X_train, y_train, batch_size = 16, epochs = 23, validation_data=(X_test,y_test))\n",
    "rms_time = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrike([ann_rms], X_test, y_test, [rms_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(rms_history.history[\"accuracy\"]))\n",
    "plt.plot(pd.DataFrame(rms_history.history[\"val_accuracy\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pd.DataFrame(rms_history.history[\"loss\"]))\n",
    "plt.plot(pd.DataFrame(rms_history.history[\"val_loss\"]))\n",
    "plt.figure(figsize=(6,6), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ann_adam,ann_adamax,ann_adagrad,ann_nadam,ann_sgd,ann_rms]\n",
    "times = [adam_time,adamax_time,adagrad_time, nadam_time, sgd_time,rms_time]\n",
    "histories = [adam_history,adamax_history,adagrad_history,nadam_history,sgd_history,rms_history]\n",
    "metrike_table(models, X_test, y_test, times, histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.save(f'../saved_models/rain_tommorow/{type(model.optimizer).__name__}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO/71HmJztjHpR9Q3DXpRZQ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "k_nearest_neighbors.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "3d99c4308d8dc5f8428d85b97a5a8546e380c637fba7a2e47370ff9a62ec2985"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
